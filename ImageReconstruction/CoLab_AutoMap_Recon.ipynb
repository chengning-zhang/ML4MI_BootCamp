{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CoLab_AutoMap_Recon.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmjohnson3/ML4MI_Bootcamp_Development/blob/master/ImageReconstruction/CoLab_AutoMap_Recon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sQfkzl7ZyVIO"
      },
      "source": [
        "This is an MRI based reconstruction demo, for 2D MRI data. The network is relatively similar to the recent AutoMap technique (https://arxiv.org/abs/1704.08841). This is a relatively 'brute force' aproach to image reconstruction in which the transoform is given no direct knowledge of the physics (although the network architecture is a bit tuned to the problem). In this work, we are assuming one direction is fully sampled (i.e. frequency encoded).\n",
        "\n",
        "# MRI Sampling\n",
        "In MRI the data is often discretely Fourier transoformed in one direction leading to the discretized signal model:\n",
        "\n",
        "$s(k)=\\sum_{j=1}^{N}\\rho (x_j)e^{i2\\pi kx}$\n",
        "\n",
        "The expected reconstruction for fully sampled data is an inverse discrete Fourier transform:\n",
        "\n",
        "$s(x)=\\sum_{j=1}^{N}s(k_j)e^{i2\\pi k_j x}$\n",
        "\n",
        "# Questions to think about:\n",
        "1) What is the minimal network architecture to compute a DFT?\n",
        "\n",
        "2) What is the apropriate loss function?\n",
        "\n",
        "3) What is the role of the convolutional layers? When are they needed?\n",
        "\n",
        "4) What is the network learning if you train on natural images?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEeJpTYyyVIQ",
        "colab": {}
      },
      "source": [
        "''' \n",
        "In python you need to import libraries in order to use them. \n",
        "'''\n",
        "\n",
        "# Import tensorflow ( we will use keras from tensorflow)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load Keras\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Utilities\n",
        "import numpy as np\n",
        "import math \n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vi9ablPpyVIT"
      },
      "source": [
        "# Training Images\n",
        "We are training this network using a simulation enviroment. Images are grabbed from a very common database of pictures of animals. We then simulate the image to MRI raw data conversion. Cifar100 is a set of 32x32 RGB images which is available from the Keras datasets api. We are discarding the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIIWqihvqkcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkyR05heyVIV",
        "colab": {}
      },
      "source": [
        "!echo \"Copying Data Locally (Image Synthesis)\"\n",
        "!tar xf \"/content/drive/My Drive/ML4MI_BOOTCAMP_DATA/ImageSynthesis.tar\" --directory /home/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZFxAwy-rUsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Subsample to reduce memory and computational burden\n",
        "subsample = 2\n",
        "\n",
        "# load training, validation, and testing data\n",
        "# adding a singleton dimension\n",
        "import h5py\n",
        "with h5py.File('/home/ImageSynthesis/data/ImageTranslationData.hdf5','r') as hf:\n",
        "    \n",
        "    # Stack the data from two constrasts\n",
        "    x_train = np.array(hf['trainX'])[:,::subsample,::subsample]\n",
        "    x_train = np.concatenate((x_train,np.array(hf['trainY'])[:,::subsample,::subsample]),axis=0)\n",
        "    \n",
        "    # Stack the data from two constrasts (validate)\n",
        "    x_val = np.array(hf['valX'])[:,::subsample,::subsample]\n",
        "    x_val = np.concatenate((x_val,np.array(hf['valX'])[:,::subsample,::subsample]),axis=0)\n",
        "\n",
        "# Input images are Dicoms which are magnitude, add 2nd channel of zeros\n",
        "x_train = np.stack((x_train,np.zeros(x_train.shape,dtype=x_train.dtype)), -1)\n",
        "x_val = np.stack((x_val,np.zeros(x_val.shape,dtype=x_train.dtype)), -1)\n",
        "\n",
        "print(f'Validate Dataset Size {x_val.shape}')\n",
        "print(f'Train Dataset Size {x_train.shape}')\n",
        "N = x_train.shape[-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b-GYZ_9yyVIX",
        "colab": {}
      },
      "source": [
        "# This is a montage maker along 1st dim\n",
        "def montage( img_in, size=(3,5) ):\n",
        "    for j in range(size[0]):\n",
        "        plot_image = img_in[0+size[1]*j,:,:]\n",
        "        for i in range(size[1]-1):\n",
        "            plot_image = np.concatenate((plot_image, img_in[1+i+size[1]*j,:,:]), axis=1)\n",
        "        \n",
        "        if j == 0:\n",
        "            img = plot_image\n",
        "        else:\n",
        "            img = np.concatenate((img,plot_image),axis=0)\n",
        "    return img\n",
        "  \n",
        "def complex_to_channels( img_in):\n",
        "  return(np.stack(img_in.real,img_in.imag))\n",
        "  \n",
        "def channels_to_complex( img_in):\n",
        "  return(img_in[...,0]+1j*img_in[...,1])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JdaPO4_syVIa"
      },
      "source": [
        "# Simulate Sampling\n",
        "MRI data generation is aproximately dsicrete sampling of a continous Fourier transform the the data. In this example, we are using a Discrete Fourier transform to aproximate this. We also consider the case when we randomly remove data points. This would allow us to go faster and is used in compressed sensing application ( e.g. https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.21391 ). Noise is added a complex, white, gaussian noise (MRI noise is so called Johnson/Nyquist noise). Things to try:\n",
        "\n",
        "1) Add higher levels of noise. What happens to the training rate and output images? \n",
        "\n",
        "2) Increase the undersampling rate. How does the neural network compare to traditional aproaches? \n",
        "\n",
        "3) Comment the FFT shift, does the network still learn the transform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7XdM9OkvyVIc",
        "colab": {}
      },
      "source": [
        "'''\n",
        "The creates a sampling mask which can be used to subsample the data.\n",
        "'''\n",
        "\n",
        "# Get the number of phase encodes\n",
        "undersample_factor = 1.0 \n",
        "noise_level = 0.001; \n",
        "\n",
        "number_phase_encodes = int(N/undersample_factor)\n",
        "print('Using ' + str(number_phase_encodes) + ' phase encode')\n",
        "\n",
        "# Create a random mask to resample the data\n",
        "idx = np.full(N, False)\n",
        "idx[:number_phase_encodes] = True\n",
        "np.random.shuffle(idx)\n",
        "sampling_mask = idx\n",
        "\n",
        "'''\n",
        "Fourier transform in 3rd dimension (Ny) followed by an FFT shift \n",
        "'''\n",
        "Nexamples = x_train.shape[0]\n",
        "kspace_train = np.zeros((Nexamples,N,number_phase_encodes,2),x_train.dtype)\n",
        "for example in range(x_train.shape[0]):\n",
        "  \n",
        "  if example % 1000 == 0:\n",
        "    print(f'Working on example {example} of {Nexamples}')\n",
        "      \n",
        "  # Grab one image\n",
        "  temp = x_train[example,:,:,0] + 1j*x_train[example,:,:,1]\n",
        "  \n",
        "  # Fourier Transform\n",
        "  kspace_temp = np.fft.fftn(temp,axes=(1,))/N\n",
        "  kspace_temp = np.fft.fftshift(kspace_temp,axes=(1,))\n",
        "  kspace_temp =np.stack( (kspace_temp.real, kspace_temp.imag), axis=-1)\n",
        "  \n",
        "  # Subsample\n",
        "  kspace_temp = kspace_temp[:,sampling_mask,:]\n",
        "  \n",
        "  # Add noise\n",
        "  kspace_temp += noise_level*np.random.randn(*kspace_temp.shape)\n",
        "\n",
        "  # Put back\n",
        "  kspace_train[example,:,:,:] = kspace_temp\n",
        "  \n",
        "print('Dimensions of training data are ' + str(kspace_train.shape) + '[ Examples x Nx x Ny x Channels]')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Fourier transform in 3rd dimension (Ny) followed by an FFT shift \n",
        "'''\n",
        "Nexamples = x_val.shape[0]\n",
        "kspace_val = np.zeros((Nexamples,N,number_phase_encodes,2),x_train.dtype)\n",
        "for example in range(x_val.shape[0]):\n",
        "  \n",
        "  if example % 1000 == 0:\n",
        "    print(f'Working on example {example} of {Nexamples}')\n",
        "      \n",
        "  # Grab one image\n",
        "  temp = x_val[example,:,:,0] + 1j*x_val[example,:,:,1]\n",
        "  \n",
        "  # Fourier Transform\n",
        "  kspace_temp = np.fft.fftn(temp,axes=(1,))/N\n",
        "  kspace_temp = np.fft.fftshift(kspace_temp,axes=(1,))\n",
        "  kspace_temp =np.stack( (kspace_temp.real, kspace_temp.imag), axis=-1)\n",
        "  \n",
        "  # Subsample\n",
        "  kspace_temp = kspace_temp[:,sampling_mask,:]\n",
        "  \n",
        "  # Add noise\n",
        "  kspace_temp += noise_level*np.random.randn(*kspace_temp.shape)\n",
        "\n",
        "  # Put back\n",
        "  kspace_val[example,:,:,:] = kspace_temp\n",
        "  \n",
        "print('Dimensions of training data are ' + str(kspace_val.shape) + '[ Examples x Nx x Ny x Channels]')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rypEBBdfyVIl",
        "colab": {}
      },
      "source": [
        "example = 400\n",
        "\n",
        "# Show one image and k-space pair(should be whale)\n",
        "img = x_train[example,:,:,0] + 1j*x_train[example,:,:,1]\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.abs(img),cmap='gray')\n",
        "plt.title('Grayscale')\n",
        "\n",
        "img = kspace_train[example,:,:,0] + 1j*kspace_train[example,:,:,1]\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.abs(img),cmap='gray')\n",
        "plt.title('K-Space (1D FFT)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NYe5C1eayVIq"
      },
      "source": [
        "# Build the network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WEykndHfyVIr",
        "colab": {}
      },
      "source": [
        "# Build functional model\n",
        "inputs = Input(shape=(N,number_phase_encodes,2), dtype='float32')\n",
        "x = keras.layers.Conv2D(2*N,kernel_size=(1,number_phase_encodes),padding='valid',activation='linear', use_bias=False)(inputs)\n",
        "x = keras.layers.Permute((1,3,2))(x)\n",
        "x = keras.layers.Conv2D(2*N,kernel_size=(1,2*N),activation='linear',padding='valid',use_bias=False)(x)\n",
        "x = keras.layers.Reshape((N,N,2))(x)\n",
        "\n",
        "#x = Conv2D(8,kernel_size=(3,3),activation='relu',padding='same',use_bias=True)(x)\n",
        "#x = Conv2D(8,kernel_size=(3,3),activation='relu',padding='same',use_bias=True)(x)\n",
        "#x = Conv2D(2,kernel_size=(3,3),activation='relu',padding='same',name='out_image',use_bias=True)(x)\n",
        "\n",
        "# Recon Network\n",
        "model = Model(inputs=inputs,outputs=x)\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='mean_squared_error')\n",
        "\n",
        "# Print a summary\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0FarDmdyVIu"
      },
      "source": [
        "# Build a callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YAqhZ0b3yVIv",
        "colab": {}
      },
      "source": [
        "'''\n",
        "    This is a traing callback that the fitting algorithm will run during training\n",
        "'''\n",
        "class TraingCallback(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.fig = plt.figure(figsize=(10,3))\n",
        "        self.logs = []\n",
        "        self.floor_epoch = 0\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    #def on_train_end( self, logs={}):\n",
        "        # Do nothing\n",
        "        \n",
        "    #def on_batch_begin(self, batch, logs={}): \n",
        "        # Do nothing \n",
        "        \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        \n",
        "        if batch%1000==0:\n",
        "            self.losses.append(logs.get('loss'))\n",
        "            \n",
        "            clear_output(wait=True)\n",
        "            self.fig = plt.figure(figsize=(10,3))\n",
        "            \n",
        "                \n",
        "            # self.params\n",
        "            #{'verbose': 1, 'nb_epoch': 12, 'batch_size': 128, 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'], 'nb_sample': 60000, 'do_validation': True}\n",
        "            batch_size = self.params['batch_size']\n",
        "            \n",
        "            example = np.random.randint(10000)\n",
        "            example = 400 \n",
        "        \n",
        "            '''\n",
        "                Run a test case\n",
        "            '''        \n",
        "            # Test with above image\n",
        "            kspace1image = kspace_val[example,:,:,:]\n",
        "            kspace1image = np.expand_dims(kspace1image,0)\n",
        "            act_image = x_val[example,:,:,:]\n",
        "            predicted_image = np.squeeze(model.predict(x=kspace1image))\n",
        "                        \n",
        "            act_image = act_image[:,:,0] + 1j*act_image[:,:,1]\n",
        "            predicted_image = predicted_image[:,:,0] + 1j*predicted_image[:,:,1]\n",
        "            \n",
        "            plt.subplot(132)\n",
        "            plt.imshow(np.abs(predicted_image), cmap='gray',vmin=0,vmax=1)\n",
        "            plt.title('Predicted Image')\n",
        "            plt.axis('off')\n",
        "            \n",
        "            plt.subplot(133)\n",
        "            plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
        "            plt.title('True Image')\n",
        "            plt.axis('off')\n",
        "            \n",
        "            # Using just this one image to get a loss\n",
        "            temp = x_val[example,:,:,:]\n",
        "            temp = np.expand_dims(temp,0)\n",
        "            self.val_losses.append( model.evaluate(x=kspace1image,y=temp,verbose=False))\n",
        "            \n",
        "            '''\n",
        "            Plot the Losses \n",
        "            '''\n",
        "            plt.subplot(131)\n",
        "            plt.semilogy(self.losses, label=\"Loss\")\n",
        "            plt.semilogy(self.val_losses, label=\"Loss (test image)\")\n",
        "            plt.legend()\n",
        "            \n",
        "            print('Epoch = ' + str(self.floor_epoch) + 'Loss = ' + str(logs.get('loss')) )\n",
        "            plt.show();\n",
        "            \n",
        "    def on_epoch_begin(self,epoch,logs={}):\n",
        "        self.floor_epoch = epoch\n",
        "            \n",
        "    #def on_epoch_end(self,epoch,logs={}):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VNWmO6ZLyVI0"
      },
      "source": [
        "# Run the model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpLk8hSVyVI1",
        "colab": {}
      },
      "source": [
        "batch_size  = 2\n",
        "\n",
        "# Create the callback object \n",
        "training_callback = TraingCallback()\n",
        "\n",
        "# Run model fit\n",
        "hist = model.fit(x=kspace_train, # Input to NN\n",
        "                 y=x_train, # Expected output\n",
        "                 batch_size=batch_size, # Minibatch size\n",
        "                 epochs=10, # Times to raster through data\n",
        "                 callbacks=[training_callback],  # Run this function during training\n",
        "                 shuffle=True,\n",
        "                 verbose=False\n",
        "                );\n",
        "\n",
        "model.save(\"TrainedModel.h5\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FItk3W_byVI4",
        "colab": {}
      },
      "source": [
        "example = 400\n",
        "\n",
        "# Test with synthetic data\n",
        "kspace = kspace_val[example,...]\n",
        "kspace = np.expand_dims(kspace,0)\n",
        "\n",
        "image = x_val[example,...]\n",
        "image = np.expand_dims(image,0)\n",
        "\n",
        "\n",
        "predicted_image = np.squeeze(model.predict(x=kspace))\n",
        "error = model.evaluate(kspace,image)\n",
        "\n",
        "# Convert to complex\n",
        "predicted_image = channels_to_complex(predicted_image)\n",
        "act_image = channels_to_complex(x_val[example,...])\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(11, 3), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.subplot(131)\n",
        "plt.imshow(np.abs(predicted_image),cmap='gray',vmin=0,vmax=1)\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.title('Predicted')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.title('True Image')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.imshow(np.abs(act_image-predicted_image),cmap='gray',vmin=0)\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.title('Difference Image')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-txDIz5lyVI9"
      },
      "source": [
        "# Compare to least squares solution with data\n",
        "Here we compare to an alterantive aproach, regularied least squares. In this technique, we build an encoding matrix which simulates the data acquisition. Then we minimize:\n",
        "\n",
        "$\\parallel Ex-d \\parallel_2 +  \\lambda \\parallel x \\parallel_2$\n",
        "\n",
        "Where $\\lambda$ is a factor that regularizes the solution when its illposed ( see https://en.wikipedia.org/wiki/Tikhonov_regularization ). The solution to this set of equations is:\n",
        "\n",
        "$ \\widetilde{x} = (E^hE + \\lambda I)^{-1}E^hd$\n",
        "\n",
        "Where I is an identity matrix. Similar to the neural network this is an aproximate solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sfsr-k_-yVI_",
        "colab": {}
      },
      "source": [
        "# Lets also solve this a different way using a matrix inverse\n",
        "def DFT_matrix(N):\n",
        "    i, j = np.meshgrid(np.arange(N), np.arange(N))\n",
        "    omega = np.exp( 2 * math.pi * 1J / N )\n",
        "    W = np.power( omega, i * j ) / N #math.sqrt(N)\n",
        "    return W\n",
        "\n",
        "E = DFT_matrix(N)\n",
        "E = np.fft.fftshift(E,axes=(0,))\n",
        "E = E[idx,:]\n",
        "\n",
        "# Grab the data\n",
        "D = np.matrix.getH(channels_to_complex(kspace_val[400,...]))\n",
        "\n",
        "# Solve for psuedo inverse\n",
        "Eh = np.matrix.getH(E)\n",
        "EhE = np.matmul(Eh,E)\n",
        "Ei = np.linalg.inv(EhE + 0.00001*np.identity(N))\n",
        "EiEh = np.matmul(Ei,Eh)\n",
        "\n",
        "linear_algebra_prediction = np.transpose(np.matmul(EiEh,D))\n",
        "    \n",
        "plt.figure(figsize=(11, 11), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "plt.subplot(231)\n",
        "plt.imshow(np.abs(linear_algebra_prediction),cmap='gray',vmin=0)\n",
        "plt.axis('off')\n",
        "plt.title('Least Squares Solution')\n",
        "plt.subplot(234)\n",
        "plt.imshow(np.abs(linear_algebra_prediction-act_image),cmap='gray',vmin=0,vmax=0.2)\n",
        "plt.axis('off')\n",
        "plt.title('Difference Least Squares')\n",
        "\n",
        "plt.subplot(232)\n",
        "plt.imshow(np.abs(predicted_image),cmap='gray',vmin=0,vmax=1)\n",
        "plt.axis('off')\n",
        "plt.title('Neural Net Prediction')\n",
        "plt.subplot(235)\n",
        "plt.imshow(np.abs(predicted_image-act_image),cmap='gray',vmin=0,vmax=0.2)\n",
        "plt.axis('off')\n",
        "plt.title('Difference Neural Net')\n",
        "\n",
        "plt.subplot(233)\n",
        "plt.imshow(np.abs(act_image),cmap='gray',vmin=0,vmax=1)\n",
        "plt.axis('off')\n",
        "plt.title('Actual Image')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Image Domain Mean Squared Error NN = ' + str(np.sum(np.square(abs(np.squeeze(predicted_image) - act_image)))) )\n",
        "print('Image Domain Mean Squared Error LS = ' + str(np.sum(np.square(abs(linear_algebra_prediction - act_image)))) )\n",
        "\n",
        "# Lets also get the kspace error\n",
        "kspace_NN = np.matmul(E,np.squeeze(predicted_image))\n",
        "kspace_LA = np.matmul(E,linear_algebra_prediction)\n",
        "\n",
        "# Difference \n",
        "diff_kspace_NN = kspace_NN - D\n",
        "diff_kspace_LA = kspace_LA - D\n",
        "print('Kspace Mean Squared Error NN = ' + str(np.sum(np.square(abs(diff_kspace_NN)))) )\n",
        "print('Kspace Mean Squared Error LS = ' + str(np.sum(np.square(abs(diff_kspace_LA)))) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bErWlC1oyVJD"
      },
      "source": [
        "# Load real MRI data to test\n",
        "This is actual acquired MRI data from a 48 channel brain scan consisting of 15 slices. The data size is exactly the same width as the cifar100 images we used for training. Just to make things doable in a short time we are keeping everything 1D, as above.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Wsb0va1yVJE",
        "colab": {}
      },
      "source": [
        "# Load a Kspace dataset from an actual acquisition\n",
        "# From matlab size(Data) -> 256    32    48    15 \n",
        "x_mri = np.fromfile('MRI_Kspace.dat', dtype=np.complex64)\n",
        "\n",
        "# (note the reverse in reshape)\n",
        "x_mri = np.reshape(x_mri,(15,48,32,256))\n",
        "\n",
        "# Get the phase encode dimension into the last dimension\n",
        "x_mri = np.transpose(x_mri,(0,1,3,2))\n",
        "\n",
        "# FFT in the frequency encode dimension which is fully sampled\n",
        "x_mri = np.fft.fftshift(x_mri,axes=(2,))\n",
        "x_mri = np.roll(x_mri,shift=6,axis=2) \n",
        "x_mri = np.fft.fftn(x_mri,axes=(2,))\n",
        "\n",
        "# Show the image\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121)\n",
        "plt.imshow(x_mri[1,1,:,:].real,aspect=1/6)\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.title('Real of Kspace')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(x_mri[1,1,:,:].imag,aspect=1/6)\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.title('Imag of Kspace')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TDpA4fbOyVJI"
      },
      "source": [
        "# Run a traditional reconstruction \n",
        "The most common reconstruction on MRI scanners is to just do a discrete Fourier transform of the data. Just a note, the data actually has 48 recievers of the signal. We are taking the sum of sqyares to average these signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ek5-9k5dyVJJ",
        "colab": {}
      },
      "source": [
        "# Traditional recon of fully sampled data\n",
        "x_mri_full = np.fft.ifftn(x_mri,axes=(3,))\n",
        "\n",
        "# do sum of squares to average coils (detectors)\n",
        "x_mri_full = np.sum(abs(x_mri_full),axis=1)\n",
        "x_mri_full = np.sqrt(x_mri_full)\n",
        "\n",
        "# Make a montage (there are other options)\n",
        "plot_image = montage(x_mri_full[:,64:192,:])  \n",
        "    \n",
        "# Show the image\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(plot_image,aspect=1/3,interpolation='bilinear',cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('DFT of Kspace')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zFZ9MqfyVJL"
      },
      "source": [
        "# Do inference on the real MRI data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNKqr0LOyVJM",
        "colab": {}
      },
      "source": [
        "# Now lets do the inference\n",
        "real_x = x_mri.real\n",
        "imag_x = x_mri.imag\n",
        "real_x = np.reshape(real_x,(-1,32))\n",
        "imag_x = np.reshape(imag_x,(-1,32))\n",
        "x_mri_for_NN = np.stack((real_x,imag_x),axis=2)\n",
        "x_mri_for_NN = np.stack((real_x,imag_x),axis=2)\n",
        "x_mri_for_NN = x_mri_for_NN[:,sampling_mask,:]\n",
        "\n",
        "# Run model\n",
        "y_mri_NN = model.predict(x=x_mri_for_NN)\n",
        "\n",
        "# Reshape\n",
        "y_mri_NN = np.reshape( y_mri_NN,(15,48,256,32))\n",
        "\n",
        "# do sum of squares to average coils (detectors)\n",
        "y_mri_NN = np.sum(abs(y_mri_NN),axis=1)\n",
        "y_mri_NN = np.sqrt(y_mri_NN)\n",
        "\n",
        "# Make a montage (there are other options)\n",
        "plot_image = montage( y_mri_NN[:,64:192,:])\n",
        "\n",
        "# Show the image\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(plot_image,aspect=1/3,interpolation='bilinear',cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Neural network prediction from Kspace')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DB9r2kdbyVJQ",
        "colab": {}
      },
      "source": [
        "# Reshape for matrix multiple\n",
        "x_mri_for_LA = np.reshape(x_mri,(-1,32))\n",
        "x_mri_for_LA = x_mri_for_LA[:,sampling_mask]\n",
        "x_mri_for_LA = np.transpose(x_mri_for_LA)\n",
        "\n",
        "\n",
        "# Also do for Least squares estimate\n",
        "y_mri_LA = np.transpose(np.matmul(EiEh,x_mri_for_LA))\n",
        "y_mri_LA = np.fliplr( y_mri_LA )\n",
        "y_mri_LA = np.reshape( y_mri_LA,(15,48,256,32))\n",
        "\n",
        "# do sum of squares to average coils (detectors)\n",
        "y_mri_LA = np.sum(abs(y_mri_LA),axis=1)\n",
        "y_mri_LA = np.sqrt(y_mri_LA)\n",
        "\n",
        "# Make a montage (there are other options)\n",
        "plot_image = montage( y_mri_LA[:,64:192,:])\n",
        "\n",
        "# Show the image\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(plot_image,aspect=1/3,interpolation='bilinear',cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Linear algebra prediction from Kspace')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rR50C3vkyVJT"
      },
      "source": [
        "# Now compare the solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vTsV6JDcyVJT",
        "colab": {}
      },
      "source": [
        "print('Max signal truth ' + str(np.max(abs(math.sqrt(32)*x_mri_full))))\n",
        "print('Max signal NN ' + str(np.max(abs(y_mri_NN))))\n",
        "print('Max signal LA ' + str(np.max(abs(y_mri_LA)))) \n",
        "\n",
        "diff_LA = y_mri_LA - x_mri_full*math.sqrt(32)\n",
        "diff_NN = y_mri_NN - x_mri_full*math.sqrt(32)\n",
        "print('LA Error = ' + str(np.mean(np.square(abs(diff_LA)))) )\n",
        "print('NN Error = ' + str(np.mean(np.square(abs(diff_NN)))) )\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.subplot(121)\n",
        "plt.imshow(abs(diff_LA[4,64:192,:]),aspect=(1/3),vmax=1000)\n",
        "plt.axis('off')\n",
        "plt.title('Diff Linear Algebra')\n",
        "plt.colorbar()\n",
        "plt.subplot(122)\n",
        "plt.imshow(abs(diff_NN[4,64:192,:]),aspect=(1/3),vmax=1000)\n",
        "plt.axis('off')\n",
        "plt.title('Diff Neural Net')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}